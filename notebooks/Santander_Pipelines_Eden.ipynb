{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Santander Model Selection Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Pipelines for each preprocessing technique\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_regression\n",
    "from dlxtools.preprocessing import PandasRobustScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Doesn't have to be a transformer as no information bleeding through process.\n",
    "class ConstantFeatureDropper(TransformerMixin, BaseEstimator):\n",
    "    \"\"\"\n",
    "    Transformer drops features from DataFrame that \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y = None):\n",
    "        \n",
    "        #Isolate numerical columns (in secom this is all)\n",
    "        numerical_columns = X.select_dtypes([np.number]).columns\n",
    "        \n",
    "        #calculatet the standard deviation of numerical columns\n",
    "        standard_deviation = X[numerical_columns].std()\n",
    "        \n",
    "        #Indicate which columns have no standard deviation\n",
    "        self.columns_to_drop = standard_deviation[standard_deviation == 0].index           \n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return X.drop(self.columns_to_drop, axis = 'columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PCAVarThreshSelector(PCA):\n",
    "    \"\"\"\n",
    "    Description\n",
    "    -----------\n",
    "    Selects the columns that can explain a certain percentage of the variance in a data set\n",
    "    \n",
    "    Authors\n",
    "    -------\n",
    "    Eden Trainor\n",
    "    \n",
    "    Notes\n",
    "    -----\n",
    "    1. PCA has a principole component limit of 4459 components, no matter how many more features you put into\n",
    "    it this is a hrad limit of how many components it will return to you.\n",
    "  \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 n_components=None, \n",
    "                 copy=True, \n",
    "                 whiten=False, \n",
    "                 svd_solver='auto', \n",
    "                 tol=0.0, \n",
    "                 iterated_power='auto', \n",
    "                 random_state=None, \n",
    "                 explained_variance_thresh = 0.8):\n",
    "        \n",
    "        \n",
    "        super().__init__(n_components, \n",
    "                         copy, \n",
    "                         whiten, \n",
    "                         svd_solver, \n",
    "                         tol, \n",
    "                         iterated_power, \n",
    "                         random_state)\n",
    "\n",
    "        \n",
    "        #Set threshold\n",
    "        self.explained_variance_thresh = explained_variance_thresh\n",
    "        \n",
    "        #Check threshold is in valid range\n",
    "        if not (0 < explained_variance_thresh <= 1):\n",
    "            raise (ValueError('explained_variance_thresh must be between 0 and 1 (default 0.8), '.format(\n",
    "                explained_variance_thresh)))\n",
    "            \n",
    "        \n",
    "        \n",
    "    def find_nearest_index(self, array, value):\n",
    "        \"\"\"\n",
    "        Description\n",
    "        -----------\n",
    "        Finds the index of the coefficient in an array nearest a certain value.\n",
    "        \n",
    "        \n",
    "        Args\n",
    "        ----\n",
    "        array: np.ndarray, (number_of_componants,)\n",
    "            Array containing coeffficients \n",
    "        \n",
    "        value: int,\n",
    "            Index of coefficient in array closset to this value is found.\n",
    "        \n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        index: int,\n",
    "            Index of coefficient in array closest to value.\n",
    "        \"\"\"\n",
    "               \n",
    "        index = (np.abs(array - value)).argmin()\n",
    "        \n",
    "        print('{}: {} features are needed to explain {:.3f}% of the variance in the data.'.format(\n",
    "            self.__class__, \n",
    "            index, \n",
    "            array[index]*100))\n",
    "        \n",
    "        return index\n",
    "    \n",
    "        \n",
    "    def fit(self, X, y = None):\n",
    "        \"\"\"\n",
    "        Description\n",
    "        -----------\n",
    "        Fits the PCA and calculates the index threshold index of the cumulative explained variance ratio array.\n",
    "        \n",
    "        \n",
    "        Args\n",
    "        ----\n",
    "        X: DataFrame, (examples, features)\n",
    "            Pandas DataFrame containing training example features\n",
    "            \n",
    "        y: array/DataFrame, (examples,)\n",
    "            (Optional) Training example labels\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        self: PCAVarThreshSelector instance\n",
    "            Returns transfromer instance with fitted instance variables on training data.\n",
    "        \"\"\"\n",
    "        \n",
    "        assert isinstance(X, pd.DataFrame), 'input isn\\'t pandas DataFrame'\n",
    "        \n",
    "        #PCA fit the dataset\n",
    "        super().fit(X)\n",
    "        \n",
    "        #Get the cumulative explained variance ratio array (ascending order of cumulative variance explained)\n",
    "        cumulative_EVR = self.explained_variance_ratio_.cumsum()\n",
    "        \n",
    "        #Finds the index corresponding to the threshold amount of variance explained\n",
    "        self.indx = self.find_nearest_index(array = cumulative_EVR, \n",
    "                                            value = self.explained_variance_thresh)\n",
    "        \n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        \"\"\"\n",
    "        Description\n",
    "        -----------        \n",
    "        Selects all the principle components up to the threshold variance.\n",
    "        \n",
    "        \n",
    "        Args\n",
    "        ----\n",
    "        X: DataFrame, (examples, features)\n",
    "            Pandas DataFrame containing training example features\n",
    "\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self: np.ndarray, (examples, indx)\n",
    "            Array containing the minimum number of principle componants required by explained_variance_thresh.\n",
    "        \"\"\"\n",
    "        \n",
    "        assert isinstance(X, pd.DataFrame)\n",
    "        \n",
    "        #Trnasform data into principal componant mode\n",
    "        all_components =  super().transform(X)\n",
    "        \n",
    "        \n",
    "        \n",
    "        return pd.DataFrame(all_components[:, :self.indx], index = X.index)\n",
    "    \n",
    "    def fit_transform(self, X, y = None):\n",
    "        \"\"\"\n",
    "        Description\n",
    "        -----------\n",
    "        Combines fit and transform methods. \n",
    "        This is especially required in this class to overwrite the fit_transform in PCA as fit method not called in \n",
    "        PCA fit_transform method.\n",
    "        \n",
    "        Args\n",
    "        ----\n",
    "        X: DataFrame, (examples, features)\n",
    "            Pandas DataFrame containing training example features\n",
    "            \n",
    "        y: array/DataFrame, (examples,)\n",
    "            (Optional) Training example labels            \n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        self: np.ndarray, (examples, indx)\n",
    "            Array containing the minimum number of principle componants required by explained_variance_thresh.\n",
    "        \"\"\"\n",
    "                            \n",
    "        return self.fit(X, y).transform(X)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build the Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaning_pipe =  Pipeline([('cfd', ConstantFeatureDropper())])                #Drops constant columns\n",
    "\n",
    "pre_processing_pipes = Pipeline([('cp', cleaning_pipe),\n",
    "                       ('rs', PandasRobustScaler()),\n",
    "                       ('pcavts', PCAVarThreshSelector())])\n",
    "                       \n",
    "lin_reg_kwargs = {}\n",
    "\n",
    "\n",
    "model_pipe = Pipeline([\n",
    "    ('ppp', Pipeline([\n",
    "        ('cp', cleaning_pipe),\n",
    "        ('rs', PandasRobustScaler()),\n",
    "        ('pcavts', PCAVarThreshSelector(whiten = True))\n",
    "    ])),\n",
    "    ('lin_reg', LinearRegression(**lin_reg_kwargs))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a fake regressional dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_regression(n_samples = 5000, n_features = 4000, effective_rank = 150, noise = 0.25, )\n",
    "\n",
    "X = pd.DataFrame(X)\n",
    "y = pd.Series(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit and score pipeline to check it's working:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '__main__.PCAVarThreshSelector'>: 836 features are needed to explain 79.99969925387471% of the variance in the data.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('ppp', Pipeline(memory=None,\n",
       "     steps=[('cp', Pipeline(memory=None, steps=[('cfd', ConstantFeatureDropper())])), ('rs', PandasRobustScaler(copy=True, quantile_range=(25.0, 75.0),\n",
       "          with_centering=True, with_scaling=True)), ('pcavts', PCAVarThreshSelector(copy=True, explained_varian...rue))])), ('lin_reg', LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False))])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5395312685166831"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pipe.score(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
